# 并发编程

本章的目标是让你对异步并发如何工作以及它与线程并发有何不同有一个高层次的了解。我认为在进入实际操作之前，对正在发生的事情有一个良好的心智模型很重要，但如果你是那种喜欢先看一些真实代码的人，你可能想先阅读接下来的一两章，然后再回到这一章。

我们将从一些动机开始，然后涵盖[顺序编程](#sequential-execution)，[使用线程或进程编程](#processes-and-threads)，然后是[异步编程](#async-programming)。本章最后一部分是关于[并发和并行](#concurrency-and-parallelism)。

用户希望他们的计算机做多件事。有时用户希望同时做这些事情（例如，在编辑器中打字的同时听音乐应用程序）。有时同时做多个任务更有效率（例如，在大文件下载时在编辑器中完成一些工作）。有时有多个用户希望同时使用一台计算机（例如，连接到服务器的多个客户端）。

举一个更低级的例子，音乐程序可能需要在用户与用户界面 (UI) 交互时继续播放音乐。为了“继续播放音乐”，它可能需要从服务器流式传输音乐数据，将该数据从一种格式处理为另一种格式，并通过操作系统 (OS) 将处理后的数据发送到计算机的音频系统。对于用户来说，它可能需要响应用户指令向服务器发送和接收数据或命令，它可能需要向播放音乐的子系统发送信号（例如，如果用户更改曲目或暂停），它可能需要更新图形显示（例如，突出显示按钮或更改曲目名称），并且在执行所有上述操作时必须保持鼠标光标或文本输入响应。

同时做多件事（或看起来这样做）称为并发。程序（与操作系统一起）必须管理它们的并发，有很多方法可以做到这一点。我们将在本章中描述其中一些方法，但我们将从纯顺序代码开始，即根本没有并发。

## 顺序执行

大多数编程语言（包括 Rust）的默认执行模式是顺序执行。

```
do_a_thing();
println!("hello!");
do_another_thing();
```

每个语句在下一个语句开始之前完成[^obs1]。在这些语句之间没有任何事情发生[^obs2]。这听起来可能微不足道，但对于推理我们的代码来说，这是一个非常有用的属性。然而，这也意味着我们浪费了很多时间。在上面的例子中，当我们等待 `println!("hello!")` 发生时，我们可以执行 `do_another_thing()`。也许我们甚至可以同时执行所有三个语句。

每当 IO[^io-def] 发生时（使用 `println!` 打印是 IO - 它是通过调用操作系统将文本输出到控制台），程序将在执行下一个语句之前等待 IO 完成[^io-complete]。在继续执行之前等待 IO 完成会*阻塞*程序取得其他进展。阻塞 IO 是最容易使用、实现和推理的 IO 类型，但它也是效率最低的——在顺序世界中，程序在等待 IO 完成时什么也做不了。

[^obs1]: 这并不完全正确：现代编译器和 CPU 会重新组织你的代码并按它们喜欢的任何顺序运行它。顺序语句可能会以许多不同的方式重叠。然而，这对于程序本身或其用户来说永远不应该是*可观察的*。
[^obs2]: 这也不正确：即使一个程序是纯顺序的，其他程序也可能同时运行；下一节将对此进行更多讨论。
[^io-def]: IO 是输入/输出 (input/output) 的缩写。它意味着从程序到程序外部世界的任何通信。这可能是读取或写入磁盘或网络，写入终端，从键盘或鼠标获取用户输入，或与操作系统或系统中运行的另一个程序通信。IO 在并发上下文中很有趣，因为它发生的时间比程序内部可能执行的几乎任何任务都要长几个数量级。这通常意味着大量的等待，而等待时间是做其他工作的机会。
[^io-complete]: IO 究竟何时完成实际上相当复杂。从程序的角度来看，当控制权从操作系统返回时，单个 IO 调用就完成了。这通常表明数据已发送到某些硬件或其他程序，但这并不一定意味着数据实际上已写入磁盘或显示给用户等。这可能需要硬件中的更多工作或定期刷新缓存，或者另一个程序读取数据。大多数情况下我们不需要担心这一点，但意识到这一点很好。

## 进程和线程

进程和线程是操作系统提供的用于提供并发的概念。每个可执行文件有一个进程，因此支持多个进程意味着计算机可以并发运行多个程序[^proc-program]；每个进程可以有多个线程，这意味着进程*内部*也可以有并发。

处理进程和线程的方式有许多细微差别。最重要的区别是内存是在线程之间共享的，而不是在进程之间共享的[^shmem]。这意味着进程之间的通信通过某种消息传递发生，类似于在不同计算机上运行的程序之间的通信。从程序的角度来看，单个进程就是它们的整个世界；创建新进程意味着运行新程序。然而，创建新线程只是程序常规执行的一部分。

由于进程和线程之间的这些区别，它们对程序员来说感觉非常不同。但从操作系统的角度来看，它们非常相似，我们将把它们作为一个单一概念来讨论它们的属性。我们将讨论线程，但除非另有说明，否则你应该将其理解为“线程或进程”。

操作系统负责*调度*线程，这意味着它决定线程何时运行以及运行多长时间。大多数现代计算机都有多个核心，因此它们可以真正同时运行多个线程。然而，通常线程数比核心数多得多，因此操作系统将运行每个线程一小段时间，然后暂停它并运行另一个线程一段时间[^sched]。当多个线程以这种方式在单个核心上运行时，称为*交错*或*时间片*。由于操作系统选择何时暂停线程的执行，这称为*抢占式多任务处理*（这里的多任务处理仅意味着同时运行多个线程）；操作系统*抢占*线程的执行（或者更详细地说，操作系统抢占式地暂停执行。它是抢占式的，因为操作系统暂停线程以为另一个线程腾出时间，在第一个线程原本会暂停之前，以确保第二个线程可以在无法执行成为问题之前执行）。

让我们再看看 IO。当线程阻塞等待 IO 时会发生什么？在具有线程的系统中，操作系统将暂停线程（无论如何它都会等待），并在 IO 完成时再次唤醒它[^busywait]。根据调度算法，IO 完成后可能需要一段时间，直到操作系统唤醒等待 IO 的线程，因为操作系统可能会等待其他线程完成一些工作。所以现在事情效率高得多：当一个线程等待 IO 时，另一个线程（或者更有可能，由于多任务处理，许多线程）可以取得进展。但是，从执行 IO 的线程的角度来看，事情仍然是顺序的——它在开始下一个操作之前等待 IO 完成。

线程还可以通过调用 `sleep` 函数（通常带有超时）来选择暂停自己。在这种情况下，操作系统根据线程自己的请求暂停线程。类似于由于抢占或 IO 导致的暂停，操作系统稍后（超时后）将再次唤醒线程以继续执行。

当操作系统暂停一个线程并启动另一个线程（出于任何原因）时，称为*上下文切换*。被切换的上下文包括寄存器、操作系统记录和许多缓存的内容。这是一项不小的工作。加上控制权转移到操作系统并返回线程，以及使用陈旧缓存的成本，上下文切换是一项昂贵的操作。

最后，请注意，某些硬件或操作系统不支持进程或线程，这在嵌入式领域更有可能。

[^proc-program]: 从用户的角度来看，单个程序可能包含多个进程，但从操作系统的角度来看，每个进程都是一个单独的程序。
[^shmem]: 一些操作系统确实支持在进程之间共享内存，但使用它需要特殊处理，并且大多数内存不共享。
[^sched]: 操作系统究竟如何选择运行哪个线程以及运行多长时间（以及在哪个核心上），是调度的关键部分。有很多选项，既有高级策略，也有配置这些策略的选项。在这里做出正确的选择对于良好的性能至关重要，但这很复杂，我们不会在这里深入探讨。
[^busywait]: 还有另一种选择，即线程可以通过在循环中旋转直到 IO 完成来进行*忙等待*。这不是很有效，因为其他线程无法运行，并且在大多数现代系统中并不常见。你可能会在锁的实现或非常简单的嵌入式系统中遇到它。


## 异步编程

异步编程是一种并发，其高级目标与线程并发相同（同时做多件事），但实现方式不同。异步并发与线程并发之间的两大区别在于，异步并发完全在程序内部管理，无需操作系统的帮助[^threads]，并且多任务处理是协作式的而不是抢占式的[^other]（我们稍后会解释）。有许多不同的异步并发模型，我们稍后将在指南中比较它们，但现在我们将只关注 Rust 的模型。

为了将它们与线程区分开来，我们将异步并发中的执行序列称为任务（它们也被称为*绿色线程*，但这有时具有抢占式调度和实现细节（如每个任务一个堆栈）的含义）。任务在内存中的执行、调度和表示方式与线程非常不同，但对于高级直觉来说，将任务视为就像线程一样，但完全在程序内部管理，而不是由操作系统管理，这可能很有用。

在异步系统中，仍然有一个调度程序决定下一个运行哪个任务（它是程序的一部分，而不是操作系统的一部分）。然而，调度程序不能抢占任务。相反，任务必须自愿放弃控制权并允许调度另一个任务。因为任务必须合作（通过放弃控制权），这被称为协作式多任务处理。

使用协作式而不是抢占式多任务处理有许多含义：

* 在可能让出控制权的点之间，你可以保证代码将按顺序执行——你永远不会被意外暂停，
* 如果任务在让出点之间花费很长时间（例如，通过执行阻塞 IO 或执行长时间运行的计算），其他任务将无法取得进展，
* 实现调度程序要简单得多，并且调度（和上下文切换）的开销更少。

异步并发比线程并发效率高得多。内存开销要低得多，上下文切换是一个更便宜的操作——它不需要将控制权移交给操作系统并返回程序，并且要切换的数据要少得多。然而，仍然可能存在一些缓存效应——尽管操作系统的缓存（如 [TLB](https://en.wikipedia.org/wiki/Translation_lookaside_buffer)）不需要更改，但任务可能会在内存的不同部分上操作，因此新调度的任务所需的数据可能不在内存缓存中。

异步 *IO* 是阻塞 IO 的替代方案（有时称为非阻塞 IO）。异步 IO 不直接与异步并发绑定，但这两者经常一起使用。在异步 IO 中，程序通过一个系统调用发起 IO，然后可以检查或在 IO 完成时收到通知。这意味着程序可以在 IO 进行时自由地完成其他工作。在 Rust 中，异步 IO 的机制由异步运行时处理（调度程序也是运行时的一部分，我们稍后将在本书中更详细地讨论运行时，但本质上运行时只是一个负责一些基本异步事务的库）。

从整个系统的角度来看，具有线程的并发系统中的阻塞 IO 和异步并发系统中的非阻塞 IO 是相似的。在这两种情况下，IO 都需要时间，并且在 IO 发生时会完成其他工作：
- 使用线程，执行 IO 的线程向操作系统请求 IO，线程被操作系统暂停，其他线程完成工作，当 IO 完成时，操作系统唤醒线程，以便它可以继续执行 IO 的结果。
- 使用异步，执行 IO 的任务向运行时请求 IO，运行时向操作系统请求 IO，但操作系统将控制权返回给运行时。运行时暂停 IO 任务并调度其他任务以完成工作。当 IO 完成时，运行时唤醒 IO 任务，以便它可以继续执行 IO 的结果。

使用异步 IO 的优点是开销要低得多，因此系统可以支持比线程多几个数量级的任务。这使得异步并发特别适合拥有大量用户且花费大量时间等待 IO 的任务（如果它们不花费大量时间等待而是做大量的 CPU 密集型工作，那么低开销就没有那么多优势，因为瓶颈将是 CPU 和内存资源）。

线程和异步并不互斥：许多程序都使用两者。有些程序的部分最好使用线程实现，部分最好使用异步实现。例如，数据库服务器可以使用异步技术来管理与客户端的网络通信，但使用操作系统线程对数据进行计算。或者，程序可能仅使用异步并发编写，但运行时将在多个线程上执行任务。这对于程序利用多个 CPU 核心是必要的。我们稍后将在本书的许多地方介绍线程和异步任务的交集。

[^threads]: 我们将假设程序只有一个线程开始解释，但稍后会对此进行扩展。系统上可能还有其他进程在运行，但它们并不真正影响异步并发的工作方式。
[^other]: 有些编程语言（甚至库）具有在程序内部管理（无需操作系统）的并发，但使用抢占式调度程序而不是依赖线程之间的协作。Go 是一个著名的例子。这些系统不需要 `async` 和 `await` 符号，但有其他缺点，包括使与其他语言或操作系统的互操作更加困难，以及拥有重量级的运行时。非常早期的 Rust 版本有这样一个系统，但在 1.0 时没有留下任何痕迹。


## 并发和并行

到目前为止，我们一直在谈论并发（同时做，或看起来做，多件事），并且我们暗示了并行（存在多个 CPU 核心，这有助于真正同时做多件事）。这些术语有时可以互换使用，但它们是不同的概念。在本节中，我们将尝试精确定义这些术语以及它们之间的区别。我将使用简单的伪代码来说明事情。

想象一个分解成一堆子任务的单个任务：

```
task1 {
  subTask1-1()
  subTask1-2()
  ...
  subTask1-100()
}
```

让我们假装是一个执行这种伪代码的处理器。显而易见的方法是先做 `subTask1-1`，然后做 `subTask1-2`，依此类推，直到我们完成所有子任务。这是顺序执行。

现在考虑多个任务。我们如何执行它们？我们可能会开始一个任务，做所有子任务直到整个任务完成，然后开始下一个。这两个任务正在按顺序执行（每个任务中的子任务也按顺序执行）。仅看子任务，你会像这样执行它们：

```
subTask1-1()
subTask1-2()
...
subTask1-100()
subTask2-1()
subTask2-2()
...
subTask2-100()

```


或者，你可以做 `subTask1`，然后把 `task1` 放在一边（记住你做了多少），拿起下一个任务并做那个任务的第一个子任务，然后回到 `task1` 做一个子任务。这两个任务将交错，我们称之为这两个任务的并发执行。它可能看起来像：

```
subTask1-1()
subTask2-1()
subTask1-2()
subTask2-2()
...
subTask1-100()
subTask2-100()

```

除非一个任务可以观察到不同任务的结果或副作用，否则从任务的角度来看，子任务仍然是按顺序执行的。

我们没有理由将自己限制在两个任务，我们可以交错任意数量的任务并以任何顺序进行。

请注意，无论我们添加多少并发，整个工作都需要相同的时间才能完成（实际上，由于它们之间上下文切换的开销，更多的并发可能会花费更长的时间）。然而，对于给定的子任务，我们可能会比纯顺序执行更早完成它（对于用户来说，这可能会感觉更灵敏）。

现在，想象一下不仅仅是你处理任务，你还有一些处理器朋友来帮助你。你可以同时处理任务并更快地完成工作！这是*并行*执行（也是并发的）。你可能会像这样执行子任务：

```
Processor 1           Processor 2
==============        ==============
subTask1-1()          subTask2-1()
subTask1-2()          subTask2-2()
...                   ...
subTask1-100()        subTask2-100()
```

如果有两个以上的处理器，我们可以并行处理更多任务。我们还可以在每个处理器上进行一些任务交错或在处理器之间共享任务。

在实际代码中，事情要复杂一些。一些子任务（例如 IO）不需要处理器积极参与，它们只需要启动并在一段时间后收集结果。并且一些子任务可能需要来自不同任务的子任务的结果（或副作用）才能取得进展（同步）。这两种情况都限制了任务可以并发执行的有效方式，再加上确保某种公平性概念，这就是为什么调度很重要的原因。


### 愚蠢的例子够了，让我们尝试正确定义事物

并发是关于计算的顺序，并行是关于执行模式。

给定两个计算，如果我们能观察到一个发生在另一个之前，我们就说它们是顺序的（即非并发的），或者如果我们不能观察到（或者或者，这并不重要）一个发生在另一个之前，我们就说它们是并发的。

如果两个计算真正同时发生，那么它们就是并行发生的。我们可以将并行视为一种资源：可用的并行越多，在固定时间内发生的计算就越多（假设计算以相同的速度发生）。在不增加并行的情况下增加系统的并发永远不会使其更快（尽管它可以使系统更灵敏，并且可能使实现否则不切实际的优化变得可行）。

重申一下，两个计算可能一个接一个地发生（既不并发也不并行），它们的执行可能在单个 CPU 核心上交错（并发，但不并行），或者它们可能在两个核心上同时执行（并发且并行）[^p-not-c]。

另一个有用的框架[^turon]是，并发是一种组织代码的方式，而并行是一种资源。这是一个强有力的声明！并发是关于组织代码而不是执行代码，这一点很重要，因为从处理器的角度来看，没有并行的并发根本不存在。这对于异步并发特别相关，因为它完全在用户侧代码中实现——它不仅“仅仅”是关于组织代码，而且你可以通过阅读源代码轻松地向自己证明这一点。并行是一种资源也很有用，因为它提醒我们，对于并行和性能，只有处理器核心的数量很重要，而不是代码在并发方面的组织方式（例如，有多少线程）。

线程和异步系统都可以提供并发和并行。在这两种情况下，并发由代码控制（派生线程或任务），并行由调度程序控制，对于线程，调度程序是操作系统的一部分（由操作系统的 API 配置），对于异步，调度程序是运行时库的一部分（由运行时的选择、运行时的实现方式以及运行时提供给客户端代码的选项配置）。然而，由于惯例和常见默认值，存在实际差异。在线程系统中，每个并发线程都尽可能使用并行执行。在异步系统中，没有强默认值：系统可以在单个线程中运行所有任务，它可以将多个任务分配给单个线程并将该线程锁定到核心（因此任务组并行执行，但在组内每个任务并发执行，但从不与组内的其他任务并行执行），或者任务可以有或没有限制地并行运行。对于本指南的第一部分，我们将使用主要支持最后一种模型的 Tokio 运行时。即，关于并行的行为类似于线程并发。此外，我们将看到异步 Rust 中的功能，这些功能明确支持并发但不支持并行，独立于运行时。

[^p-not-c]: 计算可以是并行但非并发的吗？有点但不完全是。想象两个任务（a 和 b），每个任务包含一个子任务（1 和 2 分别属于 a 和 b）。通过使用同步，我们在子任务 1 完成之前无法启动子任务 2，并且任务 a 必须等待子任务 2 完成直到它完成。现在 a 和 b 在不同的处理器上运行。如果我们把任务看作黑匣子，我们可以说它们是并行运行的，但在某种意义上它们不是并发的，因为它们的顺序是完全确定的。然而，如果我们看子任务，我们可以看到它们既不并行也不并发。

[^turon]: 我认为这归功于 Aaron Turon，并反映在 Rust 标准库的一些设计中，例如在 [available_parallelism](https://doc.rust-lang.org/std/thread/fn.available_parallelism.html) 函数中。

## 总结

- 有许多执行模型。我们描述了顺序执行、线程和进程以及异步编程。
  - 线程是操作系统提供（并调度）的抽象。它们通常涉及抢占式多任务处理，默认情况下是并行的，并且具有相当高的管理和上下文切换开销。
  - 异步编程由用户空间运行时管理。多任务处理是协作式的。它的开销比线程低，但感觉与使用线程编程有点不同，因为它使用不同的编程原语（`async` 和 `await`，以及 futures，而不是一等线程）。
- 并发和并行是不同但密切相关的概念。
  - 并发是关于计算的顺序（如果操作的执行顺序无法观察到，则操作是并发的）。
  - 并行是关于在多个处理器上计算（如果操作真正同时发生，则操作是并行的）。
- 操作系统线程和异步编程都提供并发和并行；异步编程还可以提供灵活或细粒度并发的结构，这些结构不是大多数操作系统线程 API 的一部分。
